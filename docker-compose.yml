version: '3.8'

services:

    es-node-01:
        profiles:
          - prod
          - logs
          - stage
        container_name: es-node-01
        ports:
            - '9200:9200'
            - '9300:9300'
        environment:
            - discovery.type=single-node
        # image: 'docker.elastic.co/elasticsearch/elasticsearch:7.17.0'
        image: elasticsearch:7.17.0

    kibana-01:
        profiles:
          - prod
          - logs
          - stage
        container_name: kibana-01
        ports:
            - '5601:5601'
        environment:
            - 'ELASTICSEARCH_HOSTS=http://es-node-01:9200'
        # image: 'docker.elastic.co/kibana/kibana:7.17.0' 
        image: kibana:7.17.0
        healthcheck:
            test: ["CMD", "curl", "-f", "kibana-01:5601"]
            interval: 50s
            timeout: 50s
            retries: 5
        depends_on:
            - es-node-01

    logstash:
        profiles:
          - prod
          - logs
          - stage
        container_name: logstash-01
        volumes:
            - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro 
            - ./logstash/logstash.yaml:/usr/share/logstash/config/logstash.yml:ro 
        # image: 'docker.elastic.co/logstash/logstash:7.17.0'
        image: logstash:7.17.0
        depends_on:   
             kibana-01:
               condition: service_healthy  

    filebeat:
        profiles:
          - prod
          - logs
          - stage
        user: root
        container_name: filebeat-01
        command: --strict.perms=false
        volumes:
            - ./filebeat/filebeat.docker.yaml:/usr/share/filebeat/filebeat.yml:ro
            - /var/lib/docker/containers:/var/lib/docker/containers:ro
            - /var/run/docker.sock:/var/run/docker.sock:ro
        # image: 'docker.elastic.co/beats/filebeat:7.17.0' 
        image: filebeat:7.17.0
        depends_on:
             kibana-01:
               condition: service_healthy

    redis_memory:
        container_name: redis_memory
        profiles:
          - prod
          - logs
          - lab
          - slim
          - stage
        image: redis:alpine
        ports:
            - "6379:6379"
        healthcheck:
          test: redis-cli ping
          interval: 10s
          timeout: 5s
          retries: 3
        volumes:
          - redis-data:/data
        restart: always

    rabbitmq:
        container_name: rabbitmq
        profiles:
          - prod
          - logs
          - lab
          - slim
          - stage
        image: rabbitmq
        ports:
            - "5672:5672"
            - "15672:15672"
        healthcheck:
          test: rabbitmq-diagnostics -q ping
          interval: 10s
          timeout: 5s
          retries: 3
        restart: always

    db:
        container_name: db
        profiles:
          - prod
          - logs
          - lab
          - slim
          - stage
        image: postgres:15.1-alpine
        ports:
            - "5432:5432"
        env_file:
            - .env
        environment:
            - PGDATA=/var/lib/postgresql/data/pgdata
        volumes:
            - ./data:/var/lib/postgresql/data/pgdata
            - ./backup_restore:/backup_restore
            - ./backup/db:/backup
        healthcheck:
            test: ["CMD-SHELL", "pg_isready"]
            interval: 10s
            timeout: 5s
            retries: 5
        restart: on-failure
        command: >
          bash -c "
            chmod +x /backup_restore/backup.sh /backup_restore/restore.sh &&
            docker-entrypoint.sh postgres
          "

    pgadmin:
        container_name: pgadmin
        profiles:
          - prod
          - logs
          - slim
          - stage
        image: dpage/pgadmin4
        depends_on:
            db:
              condition: service_healthy
        env_file:
            - .env
        ports:
            - "5050:80"

    backend:
        container_name: backend
        profiles:
          - prod
          - logs
          - slim
          - stage
        build:
            context: ./backend
            dockerfile: backend.dockerfile
            target: prod
            args:
              GIT_TOKEN_PEDESIS: $GIT_TOKEN_PEDESIS
        depends_on:
            celery:
              condition: service_healthy
        env_file:
            - .env
        environment:
            - REDIS_HOST=redis_memory
            - RABBITMQ_HOST=rabbitmq
            - POSTGRES_HOST=db
        volumes:
            - ./backend/app:/app
        ports:
            - 5678:5678
        restart: on-failure

    notebook:
        container_name: notebook
        profiles:
          - prod
          - lab
          - stage
        build:
            context: ./backend
            dockerfile: backend.dockerfile
            target: notebook
            args:
              GIT_TOKEN_PEDESIS: $GIT_TOKEN_PEDESIS
        depends_on:
            celery:
              condition: service_healthy
        env_file:
            - .env
        environment:
            - REDIS_HOST=redis_memory
            - RABBITMQ_HOST=rabbitmq
            - POSTGRES_HOST=db
        ports:  
            - 8001:8888
        restart: on-failure
        volumes:
          - ./backend/app:/app
          - ./backup/ohlcv_datas:/app/back_datas
          - ./notebook/lab.ipynb:/app/lab.ipynb

    celery:
        profiles:
          - prod
          - logs
          - lab
          - slim
          - stage
        build:
            context: ./backend
            dockerfile: backend.dockerfile
            target: worker
            args:
              GIT_TOKEN_PEDESIS: $GIT_TOKEN_PEDESIS
        depends_on:
            redis_memory:
              condition: service_healthy
            rabbitmq:
              condition: service_healthy
            db:
              condition: service_healthy
        env_file:
            - .env
        environment:
            - REDIS_HOST=redis_memory
            - RABBITMQ_HOST=rabbitmq
            - POSTGRES_HOST=db
            - C_FORCE_ROOT=true
            - CELERY_BROKER_URL=amqp://rabbitmq:5672
            - CELERY_RESULT_BACKEND=redis://redis_memory:6379/1
        ports:
            - 5679:5679
        volumes:
            - ./backup/ohlcv_datas:/app/back_datas
            - ./celery_files:/app/celery_files
        healthcheck:
          test: celery -A pedesis.tasks_manager:manager inspect ping
          interval: 30s
          timeout: 10s
          retries: 5
        restart: always

    celery_beat:
        container_name: celery_beat
        profiles:
          - prod
          - logs
          - lab
          - slim
          - stage
        build:
            context: ./backend
            dockerfile: backend.dockerfile
            target: beat
            args:
              GIT_TOKEN_PEDESIS: $GIT_TOKEN_PEDESIS
        depends_on:
            celery:
              condition: service_healthy
        env_file:
            - .env
        environment:
            - REDIS_HOST=redis_memory
            - RABBITMQ_HOST=rabbitmq
            - POSTGRES_HOST=db
            - C_FORCE_ROOT=true
            - CELERY_BROKER_URL=amqp://rabbitmq:5672
            - CELERY_RESULT_BACKEND=redis://redis_memory:6379/1
        volumes:
            - ./backup/ohlcv_datas:/app/back_datas
            - ./celery_files:/app/celery_files

    flower:
        container_name: flower
        profiles:
          - prod
          - lab
          - slim
          - stage
        build:
            context: ./backend
            dockerfile: backend.dockerfile
            target: flower
            args:
              GIT_TOKEN_PEDESIS: $GIT_TOKEN_PEDESIS
              FLOWER_PORT: 5555
        env_file:
            - .env
        environment:
            - CELERY_BROKER_URL="amqp://rabbitmq:5672"
            - CELERY_BROKER_TRANSPORT_URL="amqp://rabbitmq:5672"
            - CELERY_RESULT_BACKEND="redis://redis_memory:6379/1"
            - C_FORCE_ROOT=true
        depends_on:
            celery:
              condition: service_healthy
        ports:
          - 5555:5555
        volumes:
          - ./flower-data:/data
        command: celery -A pedesis.tasks_manager:manager --broker=amqp://rabbitmq:5672 flower --persisten=True --port=5555

    prometheus:
      profiles:
        - prod
      image: prom/prometheus:latest
      container_name: prometheus
      ports:
        - 9090:9090
      volumes:
        - ./prometheus:/etc/prometheus
        - prometheus-data:/prometheus
      command: "--config.file=/etc/prometheus/prometheus.yml"
      restart: unless-stopped

    node_exporter:
      profiles:
        - prod
      image: quay.io/prometheus/node-exporter:v1.5.0
      container_name: node_exporter
      command: "--path.rootfs=/host"
      pid: host
      restart: unless-stopped
      volumes:
        - /:/host:ro,rslave

    cadvisor:
      profiles:
        - prod
      image: gcr.io/cadvisor/cadvisor:latest
      container_name: cadvisor
      ports:
      - 8080:8080
      volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      depends_on:
      - redis_memory

    grafana:
      profiles:
        - prod
      image: grafana/grafana-oss:latest
      container_name: grafana
      ports:
        - "3000:3000"
      volumes:
        - grafana-data:/var/lib/grafana
      restart: unless-stopped

    portainer:
      profiles:
        - prod
      container_name: portainer
      image: portainer/portainer-ce:latest
      ports:
        - 9000:9000
        - 9443:9443
        - 8000:8000
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock
        - portainer-data:/data
      restart: unless-stopped

volumes:
    data:
      driver: local
    celery_files:
      driver: local
    redis-data:
      driver: local
    flower-data:
      driver: local
    prometheus-data:
        driver: local
    grafana-data:
      driver: local
    portainer-data:
      driver: local
