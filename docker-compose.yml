version: '3.8'

services:

    setup:
      profiles:
        - setup
      build:
        context: setup_elk/
        args:
          ELASTIC_VERSION: ${ELASTIC_VERSION}
      init: true
      volumes:
        - ./setup_elk/entrypoint.sh:/entrypoint.sh:ro,Z
        - ./setup_elk/lib.sh:/lib.sh:ro,Z
        - ./setup_elk/roles:/roles:ro,Z
      environment:
        ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
        LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
        KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
        METRICBEAT_INTERNAL_PASSWORD: ${METRICBEAT_INTERNAL_PASSWORD:-}
        FILEBEAT_INTERNAL_PASSWORD: ${FILEBEAT_INTERNAL_PASSWORD:-}
        HEARTBEAT_INTERNAL_PASSWORD: ${HEARTBEAT_INTERNAL_PASSWORD:-}
        MONITORING_INTERNAL_PASSWORD: ${MONITORING_INTERNAL_PASSWORD:-}
        BEATS_SYSTEM_PASSWORD: ${BEATS_SYSTEM_PASSWORD:-}
      depends_on:
        - elasticsearch

    elasticsearch:
      build:
        context: elasticsearch/
        args:
          ELASTIC_VERSION: ${ELASTIC_VERSION}
      volumes:
        - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
        - elasticsearch:/usr/share/elasticsearch/data:Z
      ports:
        - 9200:9200
        - 9300:9300
      environment:
        node.name: elasticsearch
        ES_JAVA_OPTS: -Xms512m -Xmx512m
        # Bootstrap password.
        # Used to initialize the keystore during the initial startup of
        # Elasticsearch. Ignored on subsequent runs.
        ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
        # Use single node discovery in order to disable production mode and avoid bootstrap checks.
        # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
        discovery.type: single-node
      restart: unless-stopped

    logstash:
      build:
        context: logstash/
        args:
          ELASTIC_VERSION: ${ELASTIC_VERSION}
      volumes:
        - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
        - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
      ports:
        - 5044:5044
        - 50000:50000/tcp
        - 50000:50000/udp
        - 9600:9600
      environment:
        LS_JAVA_OPTS: -Xms256m -Xmx256m
        LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      depends_on:
        - elasticsearch
      restart: unless-stopped

    kibana:
      build:
        context: kibana/
        args:
          ELASTIC_VERSION: ${ELASTIC_VERSION}
      volumes:
        - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
      ports:
        - 5601:5601
      environment:
        KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
      depends_on:
        - elasticsearch
      restart: unless-stopped

    filebeat:
      build:
        context: extensions/filebeat/
        args:
          ELASTIC_VERSION: ${ELASTIC_VERSION}
      # Run as 'root' instead of 'filebeat' (uid 1000) to allow reading
      # 'docker.sock' and the host's filesystem.
      user: root
      command:
        # Log to stderr.
        - -e
        # Disable config file permissions checks. Allows mounting
        # 'config/filebeat.yml' even if it's not owned by root.
        # see: https://www.elastic.co/guide/en/beats/libbeat/current/config-file-permissions.html
        - --strict.perms=false
      volumes:
        - ./extensions/filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro,Z
        - type: bind
          source: /var/lib/docker/containers
          target: /var/lib/docker/containers
          read_only: true
        - type: bind
          source: /var/run/docker.sock
          target: /var/run/docker.sock
          read_only: true
      environment:
        FILEBEAT_INTERNAL_PASSWORD: ${FILEBEAT_INTERNAL_PASSWORD:-}
        BEATS_SYSTEM_PASSWORD: ${BEATS_SYSTEM_PASSWORD:-}
      networks:
        - elk
      depends_on:
        - elasticsearch

    redis_memory:
        image: redis:alpine
        ports:
            - "6379:6379"
        healthcheck:
          test: redis-cli ping
          interval: 10s
          timeout: 5s
          retries: 3
        volumes:
          - redis-data:/data
        restart: always

    rabbitmq:
        image: rabbitmq
        ports:
            - "5672:5672"
            - "15672:15672"
        healthcheck:
          test: rabbitmq-diagnostics -q ping
          interval: 10s
          timeout: 5s
          retries: 3
        restart: always

    db:
        image: postgres:15.1-alpine
        ports:
            - "5432:5432"
        env_file:
            - .env
        environment:
            - PGDATA=/var/lib/postgresql/data/pgdata
        volumes:
            - ./data:/var/lib/postgresql/data/pgdata
        healthcheck:
            test: ["CMD-SHELL", "pg_isready"]
            interval: 10s
            timeout: 5s
            retries: 5
        restart: on-failure

    pgadmin:
        image: dpage/pgadmin4
        depends_on:
            db:
              condition: service_healthy
        env_file:
            - .env
        ports:
            - "5050:80"

    backend:
        build:
            context: ./backend
            dockerfile: backend.dockerfile
            target: prod
            args:
              GIT_TOKEN_PEDESIS: $GIT_TOKEN_PEDESIS
        depends_on:
            celery:
              condition: service_healthy
        env_file:
            - .env
        environment:
            - REDIS_HOST=redis_memory
            - RABBITMQ_HOST=rabbitmq
            - POSTGRES_HOST=db
        volumes:
            - ./backend/app:/app
        ports:
            - 5678:5678
        restart: on-failure

    notebook:
        build:
            context: ./backend
            dockerfile: backend.dockerfile
            target: notebook
            args:
              GIT_TOKEN_PEDESIS: $GIT_TOKEN_PEDESIS
        depends_on:
            celery:
              condition: service_healthy
        env_file:
            - .env
        environment:
            - REDIS_HOST=redis_memory
            - RABBITMQ_HOST=rabbitmq
            - POSTGRES_HOST=db
        ports:  
            - 8001:8888
        restart: on-failure

    celery:
        build:
            context: ./backend
            dockerfile: celeryworker.dockerfile
            target: prod
            args:
              GIT_TOKEN_PEDESIS: $GIT_TOKEN_PEDESIS
        depends_on:
            redis_memory:
              condition: service_healthy
            rabbitmq:
              condition: service_healthy
            db:
              condition: service_healthy
        env_file:
            - .env
        environment:
            - REDIS_HOST=redis_memory
            - RABBITMQ_HOST=rabbitmq
            - POSTGRES_HOST=db
            - C_FORCE_ROOT=true
            - CELERY_BROKER_URL=amqp://rabbitmq:5672
            - CELERY_RESULT_BACKEND=redis://redis_memory:6379/1
        ports:
            - 5679:5679
        volumes:
            - ./celery-back-datas:/app/back_datas
            - ./celery_files:/app/celery_files
        healthcheck:
          test: celery -A pedesis.tasks_manager:manager inspect ping
          interval: 30s
          timeout: 10s
          retries: 5
        restart: always

    flower:
      build:
          context: ./backend
          dockerfile: celeryworker.dockerfile
          target: flower
          args:
            GIT_TOKEN_PEDESIS: $GIT_TOKEN_PEDESIS
            FLOWER_PORT: 5555
      env_file:
          - .env
      environment:
          - CELERY_BROKER_URL="amqp://rabbitmq:5672"
          - CELERY_BROKER_TRANSPORT_URL="amqp://rabbitmq:5672"
          - CELERY_RESULT_BACKEND="redis://redis_memory:6379/1"
          - C_FORCE_ROOT=true
      depends_on:
          celery:
            condition: service_healthy
      ports:
        - 5555:5555
      volumes:
        - ./flower-data:/data
      command: celery -A pedesis.tasks_manager:manager --broker=amqp://rabbitmq:5672 flower --persisten=True --port=5555

    prometheus:
      image: prom/prometheus:latest
      container_name: prometheus
      ports:
        - 9090:9090
      volumes:
        - ./prometheus:/etc/prometheus
        - prometheus-data:/prometheus
      command: "--config.file=/etc/prometheus/prometheus.yml"
      restart: unless-stopped

    node_exporter:
      image: quay.io/prometheus/node-exporter:v1.5.0
      container_name: node_exporter
      command: "--path.rootfs=/host"
      pid: host
      restart: unless-stopped
      volumes:
        - /:/host:ro,rslave

    cadvisor:
      image: gcr.io/cadvisor/cadvisor:latest
      container_name: cadvisor
      ports:
      - 8080:8080
      volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      depends_on:
      - redis_memory

    grafana:
      image: grafana/grafana-oss:latest
      container_name: grafana
      ports:
        - "3000:3000"
      volumes:
        - grafana-data:/var/lib/grafana
      restart: unless-stopped

    portainer:
      container_name: portainer
      image: portainer/portainer-ce:latest
      ports:
        - 9000:9000
        - 9443:9443
        - 8000:8000
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock
        - portainer-data:/data
      restart: unless-stopped

volumes:
    data:
      driver: local
    celery-back-datas:
      driver: local
    celery_files:
      driver: local
    redis-data:
      driver: local
    flower-data:
      driver: local
    prometheus-data:
        driver: local
    grafana-data:
      driver: local
    portainer-data:
      driver: local
    elasticsearch:
